{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Electric Propulsion System - Fault Detection using Machine Learning\n",
        "\n",
        "## Workshop Notebook\n",
        "\n",
        "This notebook demonstrates how to build a machine learning model to detect faults in an electric propulsion system (e.g., electric aircraft, UAV) using data from a Simscape digital twin.\n",
        "\n",
        "### Faults We'll Detect:\n",
        "| Label | Fault Type | Physical Cause |\n",
        "|-------|------------|----------------|\n",
        "| 0 | Healthy | Normal operation |\n",
        "| 1 | Battery Fault | Increased internal resistance (0.05 ‚Üí 0.15 Œ©) |\n",
        "| 2 | Motor Fault | Efficiency degradation (88% ‚Üí 70%) |\n",
        "| 3 | Propeller Fault | Blade damage - reduced thrust (Kt: 0.10 ‚Üí 0.06) |\n",
        "\n",
        "### System Overview:\n",
        "```\n",
        "Battery (201.6V) ‚Üí Motor & Drive (20kW) ‚Üí Propeller (0.9m) ‚Üí Thrust (~139N)\n",
        "```\n",
        "\n",
        "---\n",
        "**Author:** Electric Propulsion Digital Twin Workshop  \n",
        "**Date:** 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üì¶ Step 1: Setup and Imports\n",
        "\n",
        "First, let's import all the necessary libraries. These are pre-installed in Google Colab!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "\n",
        "# Utilities\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Plot settings\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = [10, 6]\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üìÅ Step 2: Upload Dataset\n",
        "\n",
        "Upload your `simscape_fault_dataset.csv` file from the Simscape simulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload dataset from your computer\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Please upload your 'simscape_fault_dataset.csv' file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename\n",
        "filename = list(uploaded.keys())[0]\n",
        "print(f\"\\n‚úÖ File uploaded: {filename}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üìä Step 3: Load and Explore Data\n",
        "\n",
        "Let's load the dataset and understand its structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(filename)\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"  DATASET OVERVIEW\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nüìê Shape: {df.shape[0]} samples √ó {df.shape[1]} features\")\n",
        "print(f\"\\nüìã Columns:\")\n",
        "for i, col in enumerate(df.columns):\n",
        "    print(f\"   {i+1}. {col}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display first few rows\n",
        "print(\"\\nüîç First 5 rows of data:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Statistical summary\n",
        "print(\"\\nüìà Statistical Summary:\")\n",
        "df.describe().round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Class distribution\n",
        "class_names = ['Healthy', 'Battery_Fault', 'Motor_Fault', 'Propeller_Fault']\n",
        "target_col = 'Fault Label'\n",
        "\n",
        "print(\"\\nüè∑Ô∏è Class Distribution:\")\n",
        "print(\"-\" * 40)\n",
        "for label in sorted(df[target_col].unique()):\n",
        "    count = (df[target_col] == label).sum()\n",
        "    pct = count / len(df) * 100\n",
        "    print(f\"   {class_names[int(label)]:20s} (Label {int(label)}): {count:3d} samples ({pct:5.1f}%)\")\n",
        "\n",
        "# Visualize class distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "colors = ['#2ecc71', '#e74c3c', '#f39c12', '#9b59b6']\n",
        "df[target_col].value_counts().sort_index().plot(kind='bar', color=colors)\n",
        "plt.xticks(range(4), class_names, rotation=45, ha='right')\n",
        "plt.xlabel('Fault Type')\n",
        "plt.ylabel('Number of Samples')\n",
        "plt.title('Class Distribution in Dataset')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üî¨ Step 4: Data Visualization\n",
        "\n",
        "Let's visualize how different faults affect the sensor measurements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create visualizations for key parameters\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "plot_features = ['Mean Voltage', 'Mean Current', 'Mean Speed_RPM', \n",
        "                 'Mean Thrust', 'Efficiency', 'Mechanical Power']\n",
        "\n",
        "for idx, feature in enumerate(plot_features):\n",
        "    ax = axes[idx // 3, idx % 3]\n",
        "    \n",
        "    for i, class_name in enumerate(class_names):\n",
        "        mask = df[target_col] == i\n",
        "        ax.hist(df.loc[mask, feature], bins=12, alpha=0.6, \n",
        "                label=class_name, color=colors[i])\n",
        "    \n",
        "    ax.set_xlabel(feature)\n",
        "    ax.set_ylabel('Count')\n",
        "    ax.set_title(f'{feature} by Fault Type')\n",
        "    ax.legend(loc='upper right', fontsize=8)\n",
        "\n",
        "plt.suptitle('Sensor Measurements Distribution by Fault Type', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scatter plot: Key fault indicators\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Plot 1: Voltage vs Current (Battery fault indicator)\n",
        "ax1 = axes[0]\n",
        "for i, class_name in enumerate(class_names):\n",
        "    mask = df[target_col] == i\n",
        "    ax1.scatter(df.loc[mask, 'Mean Voltage'], df.loc[mask, 'Mean Current'], \n",
        "                c=colors[i], label=class_name, alpha=0.7, s=80)\n",
        "ax1.set_xlabel('Voltage (V)')\n",
        "ax1.set_ylabel('Current (A)')\n",
        "ax1.set_title('Voltage vs Current\\n(Battery fault ‚Üí Low voltage)')\n",
        "ax1.legend()\n",
        "\n",
        "# Plot 2: Power In vs Power Out (Motor fault indicator)\n",
        "ax2 = axes[1]\n",
        "for i, class_name in enumerate(class_names):\n",
        "    mask = df[target_col] == i\n",
        "    ax2.scatter(df.loc[mask, 'Electrical Power'], df.loc[mask, 'Mechanical Power'], \n",
        "                c=colors[i], label=class_name, alpha=0.7, s=80)\n",
        "ax2.set_xlabel('Electrical Power (W)')\n",
        "ax2.set_ylabel('Mechanical Power (W)')\n",
        "ax2.set_title('Electrical vs Mechanical Power\\n(Motor fault ‚Üí Low efficiency)')\n",
        "ax2.legend()\n",
        "\n",
        "# Plot 3: Speed vs Thrust (Propeller fault indicator)\n",
        "ax3 = axes[2]\n",
        "for i, class_name in enumerate(class_names):\n",
        "    mask = df[target_col] == i\n",
        "    ax3.scatter(df.loc[mask, 'Mean Speed_RPM'], df.loc[mask, 'Mean Thrust'], \n",
        "                c=colors[i], label=class_name, alpha=0.7, s=80)\n",
        "ax3.set_xlabel('Speed (RPM)')\n",
        "ax3.set_ylabel('Thrust (N)')\n",
        "ax3.set_title('Speed vs Thrust\\n(Propeller fault ‚Üí Low thrust)')\n",
        "ax3.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüí° Key Observations:\")\n",
        "print(\"   ‚Ä¢ Battery Fault: Lower voltage at same current\")\n",
        "print(\"   ‚Ä¢ Motor Fault: Lower mechanical power for same electrical power\")\n",
        "print(\"   ‚Ä¢ Propeller Fault: Lower thrust at same RPM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ‚öôÔ∏è Step 5: Feature Engineering\n",
        "\n",
        "Create additional features that help distinguish between fault types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create enhanced dataset with derived features\n",
        "df_enhanced = df.copy()\n",
        "\n",
        "# 1. Power Ratio (efficiency indicator)\n",
        "df_enhanced['Power_Ratio'] = df_enhanced['Mechanical Power'] / (df_enhanced['Electrical Power'] + 1e-6)\n",
        "\n",
        "# 2. Thrust per unit power (propeller health)\n",
        "df_enhanced['Thrust_per_Power'] = df_enhanced['Mean Thrust'] / (df_enhanced['Mechanical Power'] + 1e-6)\n",
        "\n",
        "# 3. Current per unit torque (motor health)\n",
        "df_enhanced['Current_per_Torque'] = df_enhanced['Mean Current'] / (np.abs(df_enhanced['Mean Torque']) + 1e-6)\n",
        "\n",
        "# 4. Voltage drop percentage (battery health)\n",
        "nominal_voltage = 201.6\n",
        "df_enhanced['Voltage_Drop_Pct'] = (nominal_voltage - df_enhanced['Mean Voltage']) / nominal_voltage * 100\n",
        "\n",
        "# 5. Speed efficiency (actual vs expected)\n",
        "max_rpm = 2500\n",
        "df_enhanced['Speed_Efficiency'] = df_enhanced['Mean Speed_RPM'] / (df_enhanced['Throttle'] * max_rpm + 1e-6)\n",
        "\n",
        "print(\"‚úÖ New features created:\")\n",
        "new_features = ['Power_Ratio', 'Thrust_per_Power', 'Current_per_Torque', 'Voltage_Drop_Pct', 'Speed_Efficiency']\n",
        "for feat in new_features:\n",
        "    print(f\"   ‚Ä¢ {feat}\")\n",
        "\n",
        "print(f\"\\nüìä Total features: {len(df_enhanced.columns) - 1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üéØ Step 6: Prepare Data for Machine Learning\n",
        "\n",
        "Split data into training and testing sets, then normalize features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define features and target\n",
        "feature_cols = [col for col in df_enhanced.columns if col != target_col]\n",
        "X = df_enhanced[feature_cols].values\n",
        "y = df_enhanced[target_col].values\n",
        "\n",
        "print(f\"Features (X): {X.shape}\")\n",
        "print(f\"Target (y): {y.shape}\")\n",
        "\n",
        "# Train-test split (80-20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"\\nüì¶ Training samples: {len(X_train)}\")\n",
        "print(f\"üì¶ Testing samples: {len(X_test)}\")\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"\\n‚úÖ Features normalized using StandardScaler\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ü§ñ Step 7: Train Multiple Models\n",
        "\n",
        "Let's train several ML models and compare their performance!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define models to compare\n",
        "models = {\n",
        "    'üå≥ Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10),\n",
        "    'üå≤ Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'üöÄ Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "    'üéØ SVM (RBF)': SVC(kernel='rbf', random_state=42, probability=True),\n",
        "    'üë• KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "    'üß† Neural Network': MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=500, random_state=42)\n",
        "}\n",
        "\n",
        "# Store results\n",
        "results = {}\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"  TRAINING MODELS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Train and evaluate each model\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    \n",
        "    # Train\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    \n",
        "    # Predict\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    \n",
        "    # Metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
        "    \n",
        "    # Store\n",
        "    results[name] = {\n",
        "        'model': model,\n",
        "        'accuracy': accuracy,\n",
        "        'f1_score': f1,\n",
        "        'cv_mean': cv_scores.mean(),\n",
        "        'cv_std': cv_scores.std(),\n",
        "        'y_pred': y_pred\n",
        "    }\n",
        "    \n",
        "    print(f\"   ‚úì Accuracy: {accuracy:.2%}\")\n",
        "    print(f\"   ‚úì F1 Score: {f1:.2%}\")\n",
        "    print(f\"   ‚úì CV Score: {cv_scores.mean():.2%} (¬±{cv_scores.std():.2%})\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"  ‚úÖ ALL MODELS TRAINED!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üìä Step 8: Compare Model Performance\n",
        "\n",
        "Let's visualize and compare all models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison dataframe\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Model': list(results.keys()),\n",
        "    'Accuracy': [results[m]['accuracy'] for m in results],\n",
        "    'F1 Score': [results[m]['f1_score'] for m in results],\n",
        "    'CV Mean': [results[m]['cv_mean'] for m in results],\n",
        "    'CV Std': [results[m]['cv_std'] for m in results]\n",
        "}).sort_values('Accuracy', ascending=False)\n",
        "\n",
        "print(\"\\nüìä MODEL COMPARISON:\")\n",
        "print(\"=\"*70)\n",
        "print(comparison_df.to_string(index=False))\n",
        "\n",
        "# Find best model\n",
        "best_model_name = comparison_df.iloc[0]['Model']\n",
        "best_accuracy = comparison_df.iloc[0]['Accuracy']\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"üèÜ BEST MODEL: {best_model_name} (Accuracy: {best_accuracy:.2%})\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize model comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Bar chart of accuracy\n",
        "ax1 = axes[0]\n",
        "models_sorted = comparison_df.sort_values('Accuracy', ascending=True)\n",
        "bar_colors = ['#2ecc71' if acc == best_accuracy else '#3498db' for acc in models_sorted['Accuracy']]\n",
        "bars = ax1.barh(models_sorted['Model'], models_sorted['Accuracy'], color=bar_colors)\n",
        "ax1.set_xlabel('Accuracy', fontsize=12)\n",
        "ax1.set_title('Model Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "ax1.set_xlim([0.5, 1.05])\n",
        "\n",
        "# Add value labels\n",
        "for bar, acc in zip(bars, models_sorted['Accuracy']):\n",
        "    ax1.text(acc + 0.01, bar.get_y() + bar.get_height()/2, \n",
        "             f'{acc:.1%}', va='center', fontsize=10)\n",
        "\n",
        "# Accuracy vs CV Score\n",
        "ax2 = axes[1]\n",
        "ax2.scatter(comparison_df['Accuracy'], comparison_df['CV Mean'], s=150, c='#3498db', alpha=0.7)\n",
        "for i, row in comparison_df.iterrows():\n",
        "    ax2.annotate(row['Model'].split()[-1], (row['Accuracy'], row['CV Mean']), \n",
        "                 textcoords=\"offset points\", xytext=(0,10), ha='center', fontsize=9)\n",
        "ax2.set_xlabel('Test Accuracy', fontsize=12)\n",
        "ax2.set_ylabel('Cross-Validation Score', fontsize=12)\n",
        "ax2.set_title('Test Accuracy vs CV Score', fontsize=14, fontweight='bold')\n",
        "ax2.plot([0.5, 1], [0.5, 1], 'r--', alpha=0.5, label='Perfect consistency')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üîç Step 9: Detailed Evaluation of Best Model\n",
        "\n",
        "Let's look at the confusion matrix and classification report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get best model predictions\n",
        "best_model = results[best_model_name]['model']\n",
        "y_pred_best = results[best_model_name]['y_pred']\n",
        "\n",
        "# Classification report\n",
        "print(f\"\\nüìã CLASSIFICATION REPORT - {best_model_name}\")\n",
        "print(\"=\"*60)\n",
        "print(classification_report(y_test, y_pred_best, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix Visualization\n",
        "cm = confusion_matrix(y_test, y_pred_best)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names, yticklabels=class_names,\n",
        "            annot_kws={'size': 14})\n",
        "plt.xlabel('Predicted', fontsize=12)\n",
        "plt.ylabel('Actual', fontsize=12)\n",
        "plt.title(f'Confusion Matrix - {best_model_name}', fontsize=14, fontweight='bold')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print per-class accuracy\n",
        "print(\"\\nüéØ Per-Class Accuracy:\")\n",
        "print(\"-\" * 40)\n",
        "for i, class_name in enumerate(class_names):\n",
        "    class_mask = y_test == i\n",
        "    if class_mask.sum() > 0:\n",
        "        class_acc = (y_pred_best[class_mask] == y_test[class_mask]).mean()\n",
        "        status = \"‚úÖ\" if class_acc >= 0.9 else \"‚ö†Ô∏è\" if class_acc >= 0.7 else \"‚ùå\"\n",
        "        print(f\"   {status} {class_name:20s}: {class_acc:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üìà Step 10: Feature Importance Analysis\n",
        "\n",
        "Which features are most important for detecting faults?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get Random Forest for feature importance\n",
        "rf_model = results['üå≤ Random Forest']['model']\n",
        "importances = rf_model.feature_importances_\n",
        "\n",
        "# Sort by importance\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': feature_cols,\n",
        "    'Importance': importances\n",
        "}).sort_values('Importance', ascending=True)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 8))\n",
        "colors = plt.cm.RdYlGn(importance_df['Importance'] / importance_df['Importance'].max())\n",
        "plt.barh(importance_df['Feature'], importance_df['Importance'], color=colors)\n",
        "plt.xlabel('Importance Score', fontsize=12)\n",
        "plt.title('Feature Importance for Fault Detection', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Top 5 features\n",
        "print(\"\\nüîù TOP 5 MOST IMPORTANT FEATURES:\")\n",
        "print(\"=\"*50)\n",
        "for i, (_, row) in enumerate(importance_df.tail(5).iloc[::-1].iterrows()):\n",
        "    print(f\"   {i+1}. {row['Feature']:25s} ({row['Importance']:.1%})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üíæ Step 11: Save the Trained Model\n",
        "\n",
        "Save the model for deployment or future use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use Random Forest as final model (good balance of accuracy and interpretability)\n",
        "final_model = results['üå≤ Random Forest']['model']\n",
        "\n",
        "# Save model and scaler\n",
        "joblib.dump(final_model, 'fault_predictor_model.joblib')\n",
        "joblib.dump(scaler, 'fault_predictor_scaler.joblib')\n",
        "\n",
        "# Save feature names\n",
        "import json\n",
        "config = {\n",
        "    'feature_names': feature_cols,\n",
        "    'class_names': class_names\n",
        "}\n",
        "with open('fault_predictor_config.json', 'w') as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ Model saved successfully!\")\n",
        "print(\"   üìÅ fault_predictor_model.joblib\")\n",
        "print(\"   üìÅ fault_predictor_scaler.joblib\")\n",
        "print(\"   üìÅ fault_predictor_config.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download saved files\n",
        "print(\"\\nüì• Download the trained model files:\")\n",
        "files.download('fault_predictor_model.joblib')\n",
        "files.download('fault_predictor_scaler.joblib')\n",
        "files.download('fault_predictor_config.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üéÆ Step 12: Real-Time Fault Prediction Demo\n",
        "\n",
        "Try predicting faults with new sensor measurements!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_fault(measurements):\n",
        "    \"\"\"\n",
        "    Predict fault from sensor measurements.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    measurements : dict\n",
        "        Dictionary with keys: 'Throttle', 'Voltage', 'Current', 'Speed_RPM',\n",
        "        'Torque', 'Thrust', 'Power_Elec', 'Power_Mech', 'Efficiency'\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    dict with fault prediction and confidence\n",
        "    \"\"\"\n",
        "    # Extract base features\n",
        "    throttle = measurements['Throttle']\n",
        "    voltage = measurements['Voltage']\n",
        "    current = measurements['Current']\n",
        "    speed = measurements['Speed_RPM']\n",
        "    torque = measurements['Torque']\n",
        "    thrust = measurements['Thrust']\n",
        "    p_elec = measurements['Power_Elec']\n",
        "    p_mech = measurements['Power_Mech']\n",
        "    efficiency = measurements['Efficiency']\n",
        "    \n",
        "    # Calculate derived features\n",
        "    power_ratio = p_mech / (p_elec + 1e-6)\n",
        "    thrust_per_power = thrust / (p_mech + 1e-6)\n",
        "    current_per_torque = current / (abs(torque) + 1e-6)\n",
        "    voltage_drop_pct = (201.6 - voltage) / 201.6 * 100\n",
        "    speed_efficiency = speed / (throttle * 2500 + 1e-6)\n",
        "    \n",
        "    # Combine features\n",
        "    features = [\n",
        "        throttle, voltage, current, speed, torque, thrust,\n",
        "        p_elec, p_mech, efficiency,\n",
        "        power_ratio, thrust_per_power, current_per_torque,\n",
        "        voltage_drop_pct, speed_efficiency\n",
        "    ]\n",
        "    \n",
        "    # Scale and predict\n",
        "    X = np.array(features).reshape(1, -1)\n",
        "    X_scaled = scaler.transform(X)\n",
        "    \n",
        "    fault_label = final_model.predict(X_scaled)[0]\n",
        "    probabilities = final_model.predict_proba(X_scaled)[0]\n",
        "    \n",
        "    return {\n",
        "        'fault_label': int(fault_label),\n",
        "        'fault_name': class_names[int(fault_label)],\n",
        "        'confidence': float(max(probabilities)),\n",
        "        'probabilities': {name: f\"{prob:.1%}\" for name, prob in zip(class_names, probabilities)}\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Prediction function ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive Demo - Test different scenarios\n",
        "print(\"=\"*60)\n",
        "print(\"  üéÆ FAULT PREDICTION DEMO\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Test scenarios\n",
        "test_cases = [\n",
        "    {\n",
        "        'name': '‚úÖ Healthy System',\n",
        "        'expected': 'Healthy',\n",
        "        'data': {'Throttle': 0.75, 'Voltage': 196.0, 'Current': 95.0, 'Speed_RPM': 2350,\n",
        "                 'Torque': -68.0, 'Thrust': 125.0, 'Power_Elec': 18620, 'Power_Mech': 16010, 'Efficiency': 86.0}\n",
        "    },\n",
        "    {\n",
        "        'name': 'üîã Battery Fault (Low Voltage)',\n",
        "        'expected': 'Battery_Fault',\n",
        "        'data': {'Throttle': 0.75, 'Voltage': 183.0, 'Current': 120.0, 'Speed_RPM': 2400,\n",
        "                 'Torque': -72.0, 'Thrust': 130.0, 'Power_Elec': 21960, 'Power_Mech': 18100, 'Efficiency': 87.0}\n",
        "    },\n",
        "    {\n",
        "        'name': '‚ö° Motor Fault (Low Efficiency)',\n",
        "        'expected': 'Motor_Fault',\n",
        "        'data': {'Throttle': 0.75, 'Voltage': 195.0, 'Current': 140.0, 'Speed_RPM': 2400,\n",
        "                 'Torque': -72.0, 'Thrust': 130.0, 'Power_Elec': 27300, 'Power_Mech': 18100, 'Efficiency': 70.0}\n",
        "    },\n",
        "    {\n",
        "        'name': 'üåÄ Propeller Fault (Low Thrust)',\n",
        "        'expected': 'Propeller_Fault',\n",
        "        'data': {'Throttle': 0.75, 'Voltage': 196.0, 'Current': 95.0, 'Speed_RPM': 2350,\n",
        "                 'Torque': -68.0, 'Thrust': 75.0, 'Power_Elec': 18620, 'Power_Mech': 16010, 'Efficiency': 86.0}\n",
        "    }\n",
        "]\n",
        "\n",
        "for test in test_cases:\n",
        "    print(f\"\\n{test['name']}\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    result = predict_fault(test['data'])\n",
        "    \n",
        "    status = \"‚úÖ\" if result['fault_name'] == test['expected'] else \"‚ùå\"\n",
        "    print(f\"   Predicted: {result['fault_name']} {status}\")\n",
        "    print(f\"   Confidence: {result['confidence']:.1%}\")\n",
        "    print(f\"   Probabilities: {result['probabilities']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üéõÔ∏è Step 13: Interactive Prediction (Try Your Own Values!)\n",
        "\n",
        "Modify the values below and run the cell to predict faults."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title üéõÔ∏è Enter Your Sensor Measurements { run: \"auto\" }\n",
        "\n",
        "# Modify these values and run the cell!\n",
        "throttle = 0.75  #@param {type:\"slider\", min:0.3, max:1.0, step:0.05}\n",
        "voltage = 196.0  #@param {type:\"slider\", min:175, max:202, step:1}\n",
        "current = 100.0  #@param {type:\"slider\", min:20, max:150, step:5}\n",
        "speed_rpm = 2400  #@param {type:\"slider\", min:1500, max:2700, step:50}\n",
        "torque = -70.0  #@param {type:\"slider\", min:-80, max:-30, step:2}\n",
        "thrust = 120.0  #@param {type:\"slider\", min:50, max:150, step:5}\n",
        "efficiency = 85.0  #@param {type:\"slider\", min:65, max:92, step:1}\n",
        "\n",
        "# Calculate powers\n",
        "power_elec = voltage * current\n",
        "power_mech = power_elec * (efficiency / 100)\n",
        "\n",
        "# Create measurement dict\n",
        "my_measurements = {\n",
        "    'Throttle': throttle,\n",
        "    'Voltage': voltage,\n",
        "    'Current': current,\n",
        "    'Speed_RPM': speed_rpm,\n",
        "    'Torque': torque,\n",
        "    'Thrust': thrust,\n",
        "    'Power_Elec': power_elec,\n",
        "    'Power_Mech': power_mech,\n",
        "    'Efficiency': efficiency\n",
        "}\n",
        "\n",
        "# Predict\n",
        "result = predict_fault(my_measurements)\n",
        "\n",
        "# Display result\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"  üîç FAULT PREDICTION RESULT\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Color-coded result\n",
        "fault_icons = {'Healthy': '‚úÖ', 'Battery_Fault': 'üîã', 'Motor_Fault': '‚ö°', 'Propeller_Fault': 'üåÄ'}\n",
        "icon = fault_icons.get(result['fault_name'], '‚ùì')\n",
        "\n",
        "print(f\"\\n   {icon} Detected Fault: {result['fault_name']}\")\n",
        "print(f\"   üìä Confidence: {result['confidence']:.1%}\")\n",
        "print(f\"\\n   Probabilities:\")\n",
        "for fault, prob in result['probabilities'].items():\n",
        "    bar = '‚ñà' * int(float(prob.strip('%')) / 5)\n",
        "    print(f\"      {fault:20s}: {bar} {prob}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## üìù Summary\n",
        "\n",
        "### What We Accomplished:\n",
        "\n",
        "1. ‚úÖ Loaded and explored fault dataset from Simscape simulation\n",
        "2. ‚úÖ Visualized how different faults affect sensor measurements\n",
        "3. ‚úÖ Engineered additional features for better fault detection\n",
        "4. ‚úÖ Trained and compared 6 different ML models\n",
        "5. ‚úÖ Evaluated model performance with confusion matrix\n",
        "6. ‚úÖ Analyzed feature importance\n",
        "7. ‚úÖ Saved trained model for deployment\n",
        "8. ‚úÖ Built interactive fault prediction demo\n",
        "\n",
        "### Key Findings:\n",
        "\n",
        "| Fault Type | Key Indicator |\n",
        "|------------|---------------|\n",
        "| Battery Fault | Low voltage at high current |\n",
        "| Motor Fault | Low efficiency (high elec power, low mech power) |\n",
        "| Propeller Fault | Low thrust at normal RPM |\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "1. Collect more training data for improved accuracy\n",
        "2. Deploy model in real-time monitoring system\n",
        "3. Add severity levels for each fault type\n",
        "4. Implement early warning system\n",
        "\n",
        "---\n",
        "**Thank you for attending this workshop!** üéâ"
      ]
    }
  ]
}
